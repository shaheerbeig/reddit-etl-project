# Reddit ETL Pipeline with Airflow

This project extracts data from the Reddit API, processes it using a **Medallion Architecture (Raw ‚Üí Bronze ‚Üí Silver)**, and stores it in PostgreSQL. Orchestration is handled by **Apache Airflow**.

---

## üöÄ Features
- Extract Reddit data via API
- Transform & clean data
- Load into PostgreSQL
- Orchestrated with Airflow
- Dockerized setup

---

## ‚öôÔ∏è Setup

1. Clone the repo:
```bash
git clone https://github.com/YOUR_USERNAME/reddit-etl-project.git
cd reddit-etl-project
```
2. Environment Variables:
Create a .env file in the root folder based on .env.example:
- REDDIT_CLIENT_ID=your_client_id
- REDDIT_SECRET=your_secret
- REDDIT_USER_AGENT=your_agent
- DB_HOST=localhost
- DB_USER=postgres
- DB_PASS=yourpassword
- DB_NAME=redditdb

3. Install dependencies:
pip install -r requirements.txt

4. Start Airflow with Docker:
docker-compose up -d

5. Open Airflow UI:
http://localhost:8080

## Architecture
- Raw Layer ‚Üí Extract Reddit API data and store as-is.
- Bronze Layer ‚Üí Clean and structure raw JSON into tabular format.
- Silver Layer ‚Üí Enrich and transform data for analytics.
- PostgreSQL ‚Üí Final storage for queries and reporting.
- Airflow ‚Üí Orchestrates the entire pipeline using DAGs.

## Tech Stack
- Python ‚Üí ETL scripts
- Apache Airflow ‚Üí Workflow orchestration
- PostgreSQL ‚Üí Data storage
- Docker & Docker Compose ‚Üí Containerized setup
- PRAW (Python Reddit API Wrapper) ‚Üí Reddit API extraction